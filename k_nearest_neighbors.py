# -*- coding: utf-8 -*-
"""K-Nearest Neighbors

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_r89H-aqfxL0DEO0NsCOoIoakSx5QlV-
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn import preprocessing
# %matplotlib inline

"""
About the dataset

Imagine a telecommunications provider has segmented its customer base by service usage patterns, categorizing the customers into four groups. If demographic data can be used to predict group membership, the company can customize offers for individual prospective customers. It is a classification problem. That is, given the dataset, with predefined labels, we need to build a model to be used to predict class of a new or unknown case.

The example focuses on using demographic data, such as region, age, and marital, to predict usage patterns.

The target field, called custcat, has four possible values that correspond to the four customer groups, as follows: 1- Basic Service 2- E-Service 3- Plus Service 4- Total Service

Our objective is to build a classifier, to predict the class of unknown cases. We will use a specific type of classification called K nearest neighbour.

Lets download the dataset. To download the data, we will use !wget to download it from IBM Object Storage.

"""

# Load dataset from CSV file

url = "https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-ML0101EN-SkillsNetwork/labs/Module%203/data/teleCust1000t.csv"

df = pd.read_csv(url)
df.describe()

"""Data Visualization and Analysis"""

df.head()

df["custcat"].value_counts()

df.hist(column="income", bins=50)

# Feature Set

df.columns

X = df[['region', 'tenure','age', 'marital', 'address', 'income', 'ed', 'employ','retire', 'gender', 'reside']].values #.astype(float)
X[0:5]

# What are our labels?

y = df["custcat"].values
y[0:5]

# Normalize Data
#Data Standardization give data zero mean and unit variance, it is good practice, especially for algorithms such as KNN which is based on distance of cases:

X = preprocessing.StandardScaler().fit(X).transform(X.astype(float))
X[0:5]

# Train and Split

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, random_state=4)

print("Train Set:    ", X_train.shape,  y_train.shape)
print("Test Set :    ", X_test.shape, y_test.shape)

"""
Classification
K nearest neighbor (KNN)

"""

# Import library

from sklearn.neighbors import  KNeighborsClassifier

# Training

k = 4

# Train Model and Predict 

neigh = KNeighborsClassifier(n_neighbors=k).fit(X_train,y_train)
neigh

# Predicting

yhat = neigh.predict(X_test)
yhat[0:5]

# Accuracy evaluation

# In multilabel classification, accuracy classification score is a function that computes subset accuracy. This function is equal to the jaccard_similarity_score function. Essentially, it calculates how closely the actual labels and predicted labels are matched in the test set.

from sklearn import metrics

print("Train Set Accuracy:       ", metrics.accuracy_score(y_train, neigh.predict(X_train)))
print("Test  Set Accuracy:       ", metrics.accuracy_score(y_test,yhat))

"""What about other K?

K in KNN, is the number of nearest neighbors to examine. It is supposed to be specified by the User. So, how can we choose right value for K? The general solution is to reserve a part of your data for testing the accuracy of the model. Then chose k =1, use the training part for modeling, and calculate the accuracy of prediction using all samples in your test set. Repeat this process, increasing the k, and see which k is the best for your model.
"""

# Calculate the accuracy of KNN for different Ks.

ks = 10
mean_acc = np.zeros((ks-1))
std_acc  = np.zeros((ks-1))

for n in range (1,ks):

#Train Model and Predict 
            neigh = KNeighborsClassifier(n_neighbors = n).fit(X_train,y_train)
            yhat = neigh.predict(X_test)
            mean_acc[n-1] = metrics.accuracy_score(y_test,yhat)

            std_acc = np.std(yhat==y_test)/np.sqrt(yhat.shape[0])

            print(std_acc)

# Plot model accuracy for Different number of Neighbors

plt.plot(range(1,ks), mean_acc,"g")
plt.fill_between(range(1,ks), mean_acc - 1 * std_acc + 1* std_acc, alpha=0.10)
plt.fill_between(range(1,ks),mean_acc - 3 * std_acc,mean_acc + 3 * std_acc, alpha=0.10,color="green")
plt.legend(("Accuracy ", "+/-  1xstd",  "+/- 3xstd"))
plt.xlabel("Number of Neighbors (K)")
plt.ylabel("Accuracy")
plt.tight_layout()
plt.show()

print("The Best Accuracy was with:    ", mean_acc.max(), "with K value=     ", mean_acc.argmax()+1)